{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f55e555d-39fd-411e-82f6-1f675365345a",
   "metadata": {},
   "source": [
    "# Endpoint benchmark\n",
    "\n",
    "We run a benchmark on a xgboost model to see how much latency / throughput we can squeeze out of the MLServe.com server.\n",
    "\n",
    "We incrementally go from 1, 2, 4 and up to 32 rps achieving **32 rps at avg latency of 100ms** which is the equivalent of serving 2.8 million requests daily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53118360-6248-43c3-920e-7b7c46392462",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45051f7-70ea-456c-a24f-8ea8ab70e0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from mlserve_sdk.client import MLServeClient\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d636a4-6a67-46b3-9cce-815fef28a052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.678125\n",
      "{'inputs': [[7.7, 0.56, 0.08, 2.5, 0.114, 14.0, 46.0, 0.9971, 3.24, 0.66, 9.6]]}\n"
     ]
    }
   ],
   "source": [
    "# Load a larger dataset from OpenML (wine-quality-red ~1600 samples, 11 features)\n",
    "X, y = fetch_openml(name=\"wine-quality-red\", version=1, return_X_y=True, as_frame=True)\n",
    "y=y.astype(int)\n",
    "classes = np.unique(y)\n",
    "class_mapping = {c: i for i, c in enumerate(classes)}\n",
    "y = np.array([class_mapping[val] for val in y])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Example test data (first two samples from dataset)\n",
    "TEST_DATA = {\n",
    "    \"inputs\": [\n",
    "        X_test.iloc[0,:].values.tolist()\n",
    "    ]\n",
    "}\n",
    "print(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0e69b7-4225-41c7-8a94-6ab2bdb2fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = os.getenv(\"USERNAME\")\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "\n",
    "client = MLServeClient()\n",
    "client.login(USERNAME, TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29c039c-0f40-402b-9cfe-78f77c29cfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict_url': 'https://mlserve.com/api/v1/predict/xgb/v1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deploy(\n",
    "    model=model,\n",
    "    name=\"xgb\",\n",
    "    version=\"v1\",\n",
    "    features=list(X),\n",
    "    background_df=X.sample(100).reset_index(drop=True),\n",
    "    metrics={'accuracy':accuracy_score(y_test, y_pred)},\n",
    "    task_type='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0eebc1-5cf6-4af2-8489-f56fd385a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RPS: 1 ===\n",
      "Total requests: 10 in 10.01s\n",
      "Achieved throughput: 1.00 req/s\n",
      "Avg latency: 168.53 ms\n",
      "P50 latency: 170.39 ms\n",
      "P95 latency: 240.90 ms\n",
      "P99 latency: 252.38 ms\n",
      "\n",
      "=== RPS: 2 ===\n",
      "Total requests: 20 in 10.03s\n",
      "Achieved throughput: 1.99 req/s\n",
      "Avg latency: 153.41 ms\n",
      "P50 latency: 146.57 ms\n",
      "P95 latency: 231.60 ms\n",
      "P99 latency: 271.62 ms\n",
      "\n",
      "=== RPS: 4 ===\n",
      "Total requests: 40 in 10.05s\n",
      "Achieved throughput: 3.98 req/s\n",
      "Avg latency: 165.26 ms\n",
      "P50 latency: 157.89 ms\n",
      "P95 latency: 238.44 ms\n",
      "P99 latency: 281.19 ms\n",
      "\n",
      "=== RPS: 8 ===\n",
      "Total requests: 80 in 10.14s\n",
      "Achieved throughput: 7.89 req/s\n",
      "Avg latency: 152.33 ms\n",
      "P50 latency: 154.81 ms\n",
      "P95 latency: 172.18 ms\n",
      "P99 latency: 202.95 ms\n",
      "\n",
      "=== RPS: 16 ===\n",
      "Total requests: 160 in 10.23s\n",
      "Achieved throughput: 15.64 req/s\n",
      "Avg latency: 127.28 ms\n",
      "P50 latency: 124.16 ms\n",
      "P95 latency: 149.52 ms\n",
      "P99 latency: 245.66 ms\n",
      "\n",
      "=== RPS: 32 ===\n",
      "Total requests: 320 in 10.38s\n",
      "Achieved throughput: 30.84 req/s\n",
      "Avg latency: 101.24 ms\n",
      "P50 latency: 99.20 ms\n",
      "P95 latency: 116.06 ms\n",
      "P99 latency: 147.04 ms\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"xgb\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "\n",
    "\n",
    "async def worker(latencies):\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        # run sync predict() in a thread\n",
    "        preds = await asyncio.to_thread(client.predict, MODEL_NAME, MODEL_VERSION, TEST_DATA)\n",
    "    except Exception as e:\n",
    "        print(\"Request failed:\", e)\n",
    "    end = time.perf_counter()\n",
    "    latencies.append((end - start) * 1000)\n",
    "\n",
    "async def run_benchmark(rps: int, duration: int = 10):\n",
    "    n_requests = rps * duration\n",
    "    latencies = []\n",
    "    tasks = []\n",
    "    interval = 1.0 / rps\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(n_requests):\n",
    "        tasks.append(asyncio.create_task(worker(latencies)))\n",
    "        await asyncio.sleep(interval)\n",
    "\n",
    "    await asyncio.gather(*tasks)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return latencies, elapsed\n",
    "\n",
    "def summarize(latencies, elapsed, rps):\n",
    "    if not latencies:\n",
    "        print(\"No successful requests\")\n",
    "        return\n",
    "    print(f\"\\n=== RPS: {rps} ===\")\n",
    "    print(f\"Total requests: {len(latencies)} in {elapsed:.2f}s\")\n",
    "    print(f\"Achieved throughput: {len(latencies)/elapsed:.2f} req/s\")\n",
    "    print(f\"Avg latency: {statistics.mean(latencies):.2f} ms\")\n",
    "    print(f\"P50 latency: {statistics.median(latencies):.2f} ms\")\n",
    "    print(f\"P95 latency: {statistics.quantiles(latencies, n=20)[-1]:.2f} ms\")\n",
    "    print(f\"P99 latency: {statistics.quantiles(latencies, n=100)[-1]:.2f} ms\")\n",
    "\n",
    "async def benchmark():\n",
    "    for rps in [1, 2, 4, 8, 16, 32]:\n",
    "        latencies, elapsed = await run_benchmark(rps, duration=10)\n",
    "        summarize(latencies, elapsed, rps)\n",
    "\n",
    "# Run inside notebook\n",
    "await benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
